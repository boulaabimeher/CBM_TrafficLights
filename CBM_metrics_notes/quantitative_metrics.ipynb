{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149a55fc",
   "metadata": {},
   "source": [
    "# CBM Metrics – Quantitative Evaluation (Research Notes)\n",
    "\n",
    "This notebook provides a deep and practical explanation of the quantitative metrics\n",
    "used to evaluate Concept Bottleneck Models (CBMs).\n",
    "\n",
    "CBMs must be evaluated beyond standard accuracy. In addition to performance, we must\n",
    "measure interpretability, causal behavior, and whether the chosen concepts preserve\n",
    "task-relevant information.\n",
    "\n",
    "These notes explain:\n",
    "- What each metric measures\n",
    "- Why the metric exists\n",
    "- How to interpret its values\n",
    "- What failure modes it reveals\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Concept Bottleneck Models – Notation and Setup\n",
    "\n",
    "A Concept Bottleneck Model decomposes prediction into two explicit stages.\n",
    "\n",
    "First, the input is mapped to a set of human-interpretable concepts:\n",
    "\n",
    "$$\n",
    "\\hat{c} = g(x)\n",
    "$$\n",
    "\n",
    "Then, the predicted concepts are used to make the final task prediction:\n",
    "\n",
    "$$\n",
    "\\hat{y} = f(\\hat{c})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $x$ is the input (e.g., image, signal, text)\n",
    "- $c \\in \\mathbb{R}^K$ is a vector of $K$ concepts\n",
    "- $y$ is the task label\n",
    "- $g$ is the concept predictor\n",
    "- $f$ is the task predictor\n",
    "\n",
    "We assume access to ground-truth annotations:\n",
    "- True concepts $c$\n",
    "- True labels $y$\n",
    "\n",
    "The goal of CBMs is to enforce that predictions are mediated through concepts, enabling\n",
    "interpretability and human intervention.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Predictive Performance Metrics\n",
    "\n",
    "Predictive performance answers the question:\n",
    "\n",
    "**How accurate is the CBM?**\n",
    "\n",
    "In CBMs, accuracy must be evaluated at two distinct levels:\n",
    "1. Task-level performance\n",
    "2. Concept-level performance\n",
    "\n",
    "Evaluating only one of these is insufficient.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1 Task Predictive Performance\n",
    "\n",
    "Task predictive performance evaluates how well the CBM predicts the final task output:\n",
    "\n",
    "$$\n",
    "\\hat{y} = f(g(x))\n",
    "$$\n",
    "\n",
    "This is analogous to standard supervised learning evaluation.\n",
    "\n",
    "Common metrics include:\n",
    "- Accuracy\n",
    "- ROC-AUC\n",
    "- F1-score\n",
    "- Mean squared error (for regression)\n",
    "\n",
    "#### Why this metric matters\n",
    "\n",
    "A CBM that performs poorly on the task is not useful, regardless of interpretability.\n",
    "Task performance is therefore a **necessary condition**.\n",
    "\n",
    "#### Key limitation\n",
    "\n",
    "High task accuracy does **not** imply:\n",
    "- Concepts are meaningful\n",
    "- Concepts are causally used\n",
    "- Human intervention is effective\n",
    "\n",
    "A CBM may behave like a black box despite strong accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 Concept Predictive Performance\n",
    "\n",
    "Concept predictive performance evaluates how accurately each concept is predicted:\n",
    "\n",
    "$$\n",
    "\\hat{c}_k = g_k(x), \\quad k = 1, \\dots, K\n",
    "$$\n",
    "\n",
    "Each concept is treated as an independent prediction problem.\n",
    "\n",
    "Typical metrics include:\n",
    "- ROC-AUC per concept\n",
    "- Accuracy per concept\n",
    "- Mean ROC-AUC across concepts\n",
    "\n",
    "#### Why this metric matters\n",
    "\n",
    "Concepts are the interface between the model and humans.\n",
    "If concept predictions are unreliable:\n",
    "- Human trust is undermined\n",
    "- Interventions become ineffective\n",
    "- Interpretability claims weaken\n",
    "\n",
    "#### Critical insight\n",
    "\n",
    "High concept accuracy does **not** guarantee:\n",
    "- Correct task predictions\n",
    "- Meaningful concept usage\n",
    "\n",
    "Concepts may be predicted well but combined poorly.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Intervention Effectiveness\n",
    "\n",
    "Intervention effectiveness is the most important CBM-specific metric.\n",
    "\n",
    "It evaluates whether correcting a concept actually changes the model’s decision.\n",
    "\n",
    "This directly tests the **causal role of concepts**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1 Motivation\n",
    "\n",
    "A core promise of CBMs is human-in-the-loop correction.\n",
    "\n",
    "Example:\n",
    "- Model predicts \"no pedestrian\" and outputs \"go\"\n",
    "- A human corrects the concept to \"pedestrian present\"\n",
    "- The model should update its prediction to \"stop\"\n",
    "\n",
    "If the prediction does not change, the concept bottleneck is ineffective.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Definition of an Intervention\n",
    "\n",
    "An intervention replaces one or more predicted concepts with their ground-truth values.\n",
    "\n",
    "For a set of concept indices $I \\subseteq \\{1, \\dots, K\\}$:\n",
    "\n",
    "$$\n",
    "\\hat{c}^{(I)}_k =\n",
    "\\begin{cases}\n",
    "c_k & \\text{if } k \\in I \\\\\n",
    "\\hat{c}_k & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The task prediction after intervention is:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{\\text{intervene}} = f(\\hat{c}^{(I)})\n",
    "$$\n",
    "\n",
    "This simulates a human correcting the model’s internal reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3 Measuring Intervention Effectiveness\n",
    "\n",
    "The standard procedure is:\n",
    "1. Compute baseline task performance using predicted concepts\n",
    "2. Perform interventions on selected concepts\n",
    "3. Recompute task performance\n",
    "4. Measure the improvement\n",
    "\n",
    "Intervention effectiveness quantifies how much task performance improves after correction.\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "- Large improvement: concepts are causally important\n",
    "- Small improvement: concepts are weakly used or ignored\n",
    "\n",
    "#### Important nuance\n",
    "\n",
    "Interventions may involve:\n",
    "- Single concepts\n",
    "- Subsets of concepts\n",
    "- All concepts\n",
    "\n",
    "Results are typically averaged across samples and intervention sets.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Concept Completeness\n",
    "\n",
    "Concept completeness evaluates whether the chosen concept set contains sufficient\n",
    "information to solve the task.\n",
    "\n",
    "This metric focuses on **concept design**, not model architecture.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.1 Motivation\n",
    "\n",
    "Using concepts restricts the information flow.\n",
    "If concepts are poorly chosen, critical task information may be lost.\n",
    "\n",
    "Concept completeness asks:\n",
    "\n",
    "**How much predictive power is preserved by using only concepts?**\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 Formal Definition\n",
    "\n",
    "Let:\n",
    "- $S_{\\text{CBM}}$ be the task performance of the CBM\n",
    "- $S_{\\text{BB}}$ be the task performance of a black-box model trained on raw inputs\n",
    "\n",
    "Concept completeness is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Completeness} =\n",
    "\\frac{S_{\\text{CBM}}}{S_{\\text{BB}}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 Interpretation of Completeness\n",
    "\n",
    "| Value | Interpretation |\n",
    "|------|---------------|\n",
    "| $\\approx 1.0$ | Concepts are sufficient |\n",
    "| $< 1.0$ | Concepts miss important information |\n",
    "| $> 1.0$ | CBM generalizes better than black-box |\n",
    "\n",
    "#### Important clarification\n",
    "\n",
    "Completeness evaluates the **concept vocabulary**, not:\n",
    "- Concept prediction accuracy\n",
    "- Training procedure\n",
    "- Task model capacity\n",
    "\n",
    "Low completeness indicates missing or insufficient concepts.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Summary of CBM Metrics\n",
    "\n",
    "| Metric | What it measures | Why it matters |\n",
    "|------|------------------|---------------|\n",
    "| Task performance | End-task accuracy | Baseline usefulness |\n",
    "| Concept performance | Concept prediction quality | Reliability of explanations |\n",
    "| Intervention effectiveness | Causal impact of concepts | True interpretability |\n",
    "| Concept completeness | Information sufficiency | Concept design quality |\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Final Takeaways\n",
    "\n",
    "- Accuracy alone is insufficient for CBM evaluation\n",
    "- Concept accuracy can be misleading\n",
    "- Intervention effectiveness tests causal reliance\n",
    "- Concept completeness evaluates concept sufficiency\n",
    "\n",
    "A CBM is only interpretable if **all metrics align**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
