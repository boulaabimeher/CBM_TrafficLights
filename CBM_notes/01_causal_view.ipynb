{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884d3e07",
   "metadata": {},
   "source": [
    "\n",
    "# Concept Bottleneck Models â€” Causal View\n",
    "\n",
    "## 1. Motivation\n",
    "\n",
    "Traditional deep learning models learn a direct mapping:\n",
    "\n",
    "$$\n",
    "X \\rightarrow Y\n",
    "$$\n",
    "\n",
    "where internal representations are opaque.\n",
    "\n",
    "Concept Bottleneck Models (CBMs) explicitly introduce **interpretable concepts** as intermediate variables, enforcing structured reasoning.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d3e3fe",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Causal Graph\n",
    "\n",
    "The CBM assumes the following causal structure:\n",
    "\n",
    "$$\n",
    "X \\rightarrow C \\rightarrow Y\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $X$ is the input (image, signal)\n",
    "- $C$ is a set of interpretable concepts\n",
    "- $Y$ is the target label\n",
    "\n",
    "This encodes the assumption that **concepts mediate the effect of input on the output**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55212b85",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Conditional Independence Assumption\n",
    "\n",
    "The causal graph implies:\n",
    "\n",
    "$$\n",
    "Y \\perp X \\mid C\n",
    "$$\n",
    "\n",
    "Meaning: once concepts are known, the raw input provides no additional information about the decision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b78ca",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Probabilistic Factorization\n",
    "\n",
    "Starting from the law of total probability:\n",
    "\n",
    "$$\n",
    "p(Y \\mid X) = \\sum_C p(Y, C \\mid X)\n",
    "$$\n",
    "\n",
    "Applying the chain rule:\n",
    "\n",
    "$$\n",
    "p(Y \\mid X) = \\sum_C p(Y \\mid C, X) p(C \\mid X)\n",
    "$$\n",
    "\n",
    "Using conditional independence:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "p(Y \\mid X) = \\sum_C p(Y \\mid C) p(C \\mid X)\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc4df9",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Interpretation\n",
    "\n",
    "- $p(C \\mid X)$: perceptual module (concept prediction)\n",
    "- $p(Y \\mid C)$: reasoning module (decision making)\n",
    "\n",
    "CBMs explicitly separate **perception** from **reasoning**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362ade7",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Causal Interventions\n",
    "\n",
    "CBMs allow interventions on concepts:\n",
    "\n",
    "$$\n",
    "do(C_i = c_i^*)\n",
    "$$\n",
    "\n",
    "Prediction under intervention:\n",
    "\n",
    "$$\n",
    "\\hat{Y} = f(C_{do})\n",
    "$$\n",
    "\n",
    "This enables **counterfactual reasoning**:\n",
    "> What would the model predict if a concept were different?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f948dc3",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Why This Matters\n",
    "\n",
    "- Explanations are **causal**, not post-hoc\n",
    "- Models are **debuggable**\n",
    "- Decisions can be **controlled**\n",
    "- Especially critical in medical and safety-critical systems\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}